A regarder: https://www.kaggle.com/yifanxie/porto-seguro-tutorial-end-to-end-ensemble

Travail en cours:
-> LGMClassifier personnalisé avec des paramètres différents (dropout, ...)  (RK: la foncion dart met un temps monstrueux, la tester a coté)

A faire:
-> Enlever les colonnes ou il y a trop de monde
-> Rajouter les colonnes drop ps_calc_

Travail fini:
-> LGBMRegressor    => SCORE ECHEC CRITIQUE, mauvais résultat
-> Pipeline LGBMClassifier    => IMPLEMENTATION ECHEC CRITIQUE, Il faut qu'Ensemble implémente fit, sinon le pipeline pour Gridsearchcv ne marche pas
-> ImproveGradientBoosting avec CVgridsearch  => RUN TIME ECHEC CRITIQUE, trop long car cela ne doit pas etre optimisé (autant travaillé avec lightgbm)
-> gridsearch avec lightgbm sans method ensemble créé à la main  SCORE ECHEC CRITIQUE




Rk diverses:
-Replace -1 par nan
-Essayer de drop les colonnes ou il y a beaucoup de -1
-Essayer d'autres method de lightgbm  (http://lightgbm.readthedocs.io/en/latest/Python-API.html#lightgbm.LGBMClassifier)
	--CV
	--LGBMRegressor
	--LGBMRanker

Commentaire NewMethod:
-Pk drop les colonnes avec ps_calc_  ?


Feature design -> https://www.kaggle.com/scirpus/big-gp/code

LGBMClassifier.py  ->   https://www.kaggle.com/arpitajena/top-200-on-lb-0-287-lgbm-avg-of-kernel-outputs  (https://www.kaggle.com/arpitajena/lb-0-287-lgbm-avg-of-kernel-outputs)
NewMethod2.py  ->  https://www.kaggle.com/the1owl/forza-baseline
